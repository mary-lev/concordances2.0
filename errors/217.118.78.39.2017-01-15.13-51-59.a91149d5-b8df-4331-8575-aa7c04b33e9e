(dp1
S'output'
p2
S"<type 'exceptions.UnicodeDecodeError'> 'ascii' codec can't decode byte 0xd1 in position 0: ordinal not in range(128)"
p3
sS'layer'
p4
S'/home/concordance/web2py/applications/test/controllers/stress.py'
p5
sS'code'
p6
S'# coding: utf8\n# \xd0\xbf\xd0\xbe\xd0\xbf\xd1\x80\xd0\xbe\xd0\xb1\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x82\xd1\x8c \xd1\x87\xd1\x82\xd0\xbe-\xd0\xbb\xd0\xb8\xd0\xb1\xd0\xbe \xd0\xb2\xd0\xb8\xd0\xb4\xd0\xb0\nimport json\nimport itertools\nfrom tokenize1 import *\nimport nltk\n\ndef index():\n    filename = \'/home/concordance/web2py/applications/test/rhymes/stress/t3.txt\'\n    with open(filename, \'rb\') as f:\n        text = f.readlines()\n    newlines = []\n    words = []\n    for all in text:\n        all=all.replace(\'\\r\\n\', \'\')\n        c = all.split(\'#\')\n        newlines.append(c)\n        words.append(c[0].decode(\'utf-8\'))\n    newlines2 = [all[1].split(\',\') for all in newlines]\n    newlines_antistress = []\n    newlines_stress = []\n    for all in newlines2:\n        newlines3 = [n.replace("\'", \'\') for n in all]\n        newlines3 = [n.replace("`", \'\') for n in newlines3]\n        newlines3 = [n.replace("\xd1\x91", \'\xd0\xb5\') for n in newlines3]\n        newlines_antistress.append(newlines3)\n        newlines_stress.append(all)\n    couples = []\n    paradigma = {}\n    err = []\n    for a in xrange(0, len(newlines_antistress)-1):\n        paradigma[words[a]]={}\n        for all in xrange(0, len(newlines_antistress)-1):\n            try:\n                not_stressed_word = newlines_antistress[a][all]\n                stressed_word = newlines_stress[a][all].decode(\'utf-8\')\n                c = [not_stressed_word, stressed_word]\n                couples.append(c)\n                paradigma[words[a]][not_stressed_word]=stressed_word\n            except:\n                err.append(newlines_antistress[a])\n    f = filename.replace(\'.txt\', \'.json\')\n    with open(f, \'w\') as outfile:\n        json.dump(paradigma, outfile)\n\n    return dict(paradigma = paradigma, err=err)\n\ndef stress():\n    filename = \'/home/concordance/web2py/applications/test/rhymes/1.txt\'\n    text = open(filename, \'r\').readlines()\n    textlines = []\n    for line in text:\n        words = nltk.word_tokenize(line.lower())\n        words_new=[]\n        for all in words:\n            w = d(d.stress.form==all).select().first()\n            if w:\n                words_new.append(w.stress)\n            else:\n                words_new.append(all)\n        textlines.append(\' \'.join(words_new))\n    return dict(normal=words, words_new=words_new, textlines=textlines)\n\ndef stress_db():\n    filename = \'/home/concordance/web2py/applications/test/rhymes/stress/zh.json\'\n    with open(filename, \'rb\') as outfile:\n        dd = json.load(outfile)\n    l = []\n    for key, i in dd.items():\n        for word, s in i.items():\n            #l.append([key, word, s])\n            d.stress.insert(lemma = key, form = word, stress = s)\n    msg = "\xd0\x92\xd1\x81\xd0\xb5"\n    return dict(msg=msg)\n\nresponse._vars=response._caller(stress)\n'
p7
sS'snapshot'
p8
(dp9
S'exception'
p10
(dp11
S'__getslice__'
p12
S"<method-wrapper '__getslice__' of exceptions.UnicodeDecodeError object>"
p13
sS'encoding'
p14
S"'ascii'"
p15
sS'__str__'
p16
S"<method-wrapper '__str__' of exceptions.UnicodeDecodeError object>"
p17
sS'__reduce__'
p18
S'<built-in method __reduce__ of exceptions.UnicodeDecodeError object>'
p19
sS'__dict__'
p20
S'{}'
p21
sS'__sizeof__'
p22
S'<built-in method __sizeof__ of exceptions.UnicodeDecodeError object>'
p23
sS'__init__'
p24
S"<method-wrapper '__init__' of exceptions.UnicodeDecodeError object>"
p25
sS'__setattr__'
p26
S"<method-wrapper '__setattr__' of exceptions.UnicodeDecodeError object>"
p27
sS'__reduce_ex__'
p28
S'<built-in method __reduce_ex__ of exceptions.UnicodeDecodeError object>'
p29
sS'end'
p30
S'1'
sS'__new__'
p31
S'<built-in method __new__ of type object>'
p32
sS'__format__'
p33
S'<built-in method __format__ of exceptions.UnicodeDecodeError object>'
p34
sS'__class__'
p35
S"<type 'exceptions.UnicodeDecodeError'>"
p36
sS'start'
p37
S'0'
sS'__doc__'
p38
S"'Unicode decoding error.'"
p39
sS'object'
p40
S"'\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9'"
p41
sS'__getitem__'
p42
S"<method-wrapper '__getitem__' of exceptions.UnicodeDecodeError object>"
p43
sS'__setstate__'
p44
S'<built-in method __setstate__ of exceptions.UnicodeDecodeError object>'
p45
sS'__getattribute__'
p46
S"<method-wrapper '__getattribute__' of exceptions.UnicodeDecodeError object>"
p47
sS'args'
p48
S"('ascii', '\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9', 0, 1, 'ordinal not in range(128)')"
p49
sS'reason'
p50
S"'ordinal not in range(128)'"
p51
sS'__subclasshook__'
p52
S'<built-in method __subclasshook__ of type object>'
p53
sS'__unicode__'
p54
S'<built-in method __unicode__ of exceptions.UnicodeDecodeError object>'
p55
sS'__delattr__'
p56
S"<method-wrapper '__delattr__' of exceptions.UnicodeDecodeError object>"
p57
sS'__repr__'
p58
S"<method-wrapper '__repr__' of exceptions.UnicodeDecodeError object>"
p59
sS'__hash__'
p60
S"<method-wrapper '__hash__' of exceptions.UnicodeDecodeError object>"
p61
ssS'evalue'
p62
S"'ascii' codec can't decode byte 0xd1 in position 0: ordinal not in range(128)"
p63
sS'request'
p64
cgluon.html
XML_unpickle
p65
(S'sVS\x00\x00<div><table><tr><td style="font-weight:bold;vertical-align:top;">ajax</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">application</td><td style="vertical-align:top;">:</td><td><div>test</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">args</td><td style="vertical-align:top;">:</td><td><div><table></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">cid</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">client</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">controller</td><td style="vertical-align:top;">:</td><td><div>stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">cookies</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">session_id_admin</td><td style="vertical-align:top;">:</td><td><div>46.101.16.229-66ba3a19-410e-462f-b6b9-57f04f1b0572<table><tr><td style="font-weight:bold;vertical-align:top;">comment</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">domain</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">expires</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">httponly</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">max-age</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">path</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">secure</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">version</td><td style="vertical-align:top;">:</td><td><div></div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_id_test</td><td style="vertical-align:top;">:</td><td><div>46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436<table><tr><td style="font-weight:bold;vertical-align:top;">comment</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">domain</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">expires</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">httponly</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">max-age</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">path</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">secure</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">version</td><td style="vertical-align:top;">:</td><td><div></div></td></tr></table></div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">env</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">CONTENT_LENGTH</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">CONTENT_TYPE</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">DOCUMENT_ROOT</td><td style="vertical-align:top;">:</td><td><div>/usr/local/openresty/nginx/html</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTPS</td><td style="vertical-align:top;">:</td><td><div>on</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_ACCEPT</td><td style="vertical-align:top;">:</td><td><div>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_ACCEPT_ENCODING</td><td style="vertical-align:top;">:</td><td><div>gzip, deflate, sdch, br</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_ACCEPT_LANGUAGE</td><td style="vertical-align:top;">:</td><td><div>ru,en;q=0.8,en-US;q=0.6</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_CACHE_CONTROL</td><td style="vertical-align:top;">:</td><td><div>max-age=0</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_CONNECTION</td><td style="vertical-align:top;">:</td><td><div>close</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_COOKIE</td><td style="vertical-align:top;">:</td><td><div>_ga=GA1.2.2009921225.1482865438; __utmt=1; session_id_test=46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436; __utma=134993891.2009921225.1482865438.1484476403.1484486980.11; __utmb=134993891.5.10.1484486980; __utmc=134993891; __utmz=134993891.1484355529.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); session_id_admin=46.101.16.229-66ba3a19-410e-462f-b6b9-57f04f1b0572</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_HOST</td><td style="vertical-align:top;">:</td><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_UPGRADE_INSECURE_REQUESTS</td><td style="vertical-align:top;">:</td><td><div>1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_USER_AGENT</td><td style="vertical-align:top;">:</td><td><div>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_X_FORWARDED_FOR</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">HTTP_X_REAL_IP</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">PATH_INFO</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">QUERY_STRING</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">REMOTE_ADDR</td><td style="vertical-align:top;">:</td><td><div>10.0.0.236</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">REMOTE_PORT</td><td style="vertical-align:top;">:</td><td><div>59895</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">REQUEST_METHOD</td><td style="vertical-align:top;">:</td><td><div>GET</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">REQUEST_URI</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">SCRIPT_NAME</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">SERVER_NAME</td><td style="vertical-align:top;">:</td><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">SERVER_PORT</td><td style="vertical-align:top;">:</td><td><div>443</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">SERVER_PROTOCOL</td><td style="vertical-align:top;">:</td><td><div>HTTP/1.1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">app_folders</td><td style="vertical-align:top;">:</td><td><div>set([&#x27;/home/concordance/web2py/applications/admin/&#x27;, &#x27;/home/concordance/web2py/applications/test/&#x27;])</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">applications_parent</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">content_length</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">content_type</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">db_sessions</td><td style="vertical-align:top;">:</td><td><div>set([])</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">debugging</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">document_root</td><td style="vertical-align:top;">:</td><td><div>/usr/local/openresty/nginx/html</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">gluon_parent</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_accept</td><td style="vertical-align:top;">:</td><td><div>text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_accept_encoding</td><td style="vertical-align:top;">:</td><td><div>gzip, deflate, sdch, br</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_accept_language</td><td style="vertical-align:top;">:</td><td><div>ru,en;q=0.8,en-US;q=0.6</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_cache_control</td><td style="vertical-align:top;">:</td><td><div>max-age=0</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_connection</td><td style="vertical-align:top;">:</td><td><div>close</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_cookie</td><td style="vertical-align:top;">:</td><td><div>_ga=GA1.2.2009921225.1482865438; __utmt=1; session_id_test=46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436; __utma=134993891.2009921225.1482865438.1484476403.1484486980.11; __utmb=134993891.5.10.1484486980; __utmc=134993891; __utmz=134993891.1484355529.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); session_id_admin=46.101.16.229-66ba3a19-410e-462f-b6b9-57f04f1b0572</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_host</td><td style="vertical-align:top;">:</td><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_upgrade_insecure_requests</td><td style="vertical-align:top;">:</td><td><div>1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_user_agent</td><td style="vertical-align:top;">:</td><td><div>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_x_forwarded_for</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">http_x_real_ip</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">https</td><td style="vertical-align:top;">:</td><td><div>on</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_jython</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_pypy</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_source</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">local_hosts</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>::ffff:127.0.0.1</div></td></tr><tr><td><div>::1</div></td></tr><tr><td><div>giles-liveweb6</div></td></tr><tr><td><div>50.19.109.98</div></td></tr><tr><td><div>127.0.0.1</div></td></tr><tr><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td><div>localhost</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">path_info</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">query_string</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">remote_addr</td><td style="vertical-align:top;">:</td><td><div>10.0.0.236</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">remote_port</td><td style="vertical-align:top;">:</td><td><div>59895</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">request_method</td><td style="vertical-align:top;">:</td><td><div>GET</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">request_uri</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">script_name</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">server_name</td><td style="vertical-align:top;">:</td><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">server_port</td><td style="vertical-align:top;">:</td><td><div>443</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">server_protocol</td><td style="vertical-align:top;">:</td><td><div>HTTP/1.1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">uwsgi.node</td><td style="vertical-align:top;">:</td><td><div>giles-liveweb6</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">uwsgi.version</td><td style="vertical-align:top;">:</td><td><div>2.0.5.1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">uwsgi_node</td><td style="vertical-align:top;">:</td><td><div>giles-liveweb6</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">uwsgi_version</td><td style="vertical-align:top;">:</td><td><div>2.0.5.1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">web2py_original_uri</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">web2py_path</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">web2py_version</td><td style="vertical-align:top;">:</td><td><div>2.9.5-stable+timestamp.2014.03.16.02.35.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.errors</td><td style="vertical-align:top;">:</td><td><div>&lt;uwsgi_file__bin_user_wsgi_wrapper.ErrorLogFile object at 0x7ff1d2ff8150&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.file_wrapper</td><td style="vertical-align:top;">:</td><td><div>&lt;built-in function uwsgi_sendfile&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.input</td><td style="vertical-align:top;">:</td><td><div>&lt;uwsgi._Input object at 0x7ff1c96d6228&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.multiprocess</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.multithread</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.run_once</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.url_scheme</td><td style="vertical-align:top;">:</td><td><div>https</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi.version</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>1</div></td></tr><tr><td><div>0</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_errors</td><td style="vertical-align:top;">:</td><td><div>&lt;uwsgi_file__bin_user_wsgi_wrapper.ErrorLogFile object at 0x7ff1d2ff8150&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_file_wrapper</td><td style="vertical-align:top;">:</td><td><div>&lt;built-in function uwsgi_sendfile&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_input</td><td style="vertical-align:top;">:</td><td><div>&lt;uwsgi._Input object at 0x7ff1c96d6228&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_multiprocess</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_multithread</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_run_once</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_url_scheme</td><td style="vertical-align:top;">:</td><td><div>https</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi_version</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>1</div></td></tr><tr><td><div>0</div></td></tr></table></div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">extension</td><td style="vertical-align:top;">:</td><td><div>html</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">folder</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py/applications/test/</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">function</td><td style="vertical-align:top;">:</td><td><div>stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">global_settings</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">app_folders</td><td style="vertical-align:top;">:</td><td><div>set([&#x27;/home/concordance/web2py/applications/admin/&#x27;, &#x27;/home/concordance/web2py/applications/test/&#x27;])</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">applications_parent</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">db_sessions</td><td style="vertical-align:top;">:</td><td><div>set([])</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">debugging</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">gluon_parent</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_jython</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_pypy</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_source</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">local_hosts</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>::ffff:127.0.0.1</div></td></tr><tr><td><div>::1</div></td></tr><tr><td><div>giles-liveweb6</div></td></tr><tr><td><div>50.19.109.98</div></td></tr><tr><td><div>127.0.0.1</div></td></tr><tr><td><div>concordance.pythonanywhere.com</div></td></tr><tr><td><div>localhost</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">web2py_version</td><td style="vertical-align:top;">:</td><td><div>2.9.5-stable+timestamp.2014.03.16.02.35.39</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_https</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_local</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">is_restful</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">now</td><td style="vertical-align:top;">:</td><td><div>datetime.datetime(2017, 1, 15, 13, 51, 59, 230128)</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">raw_args</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">raw_extension</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">url</td><td style="vertical-align:top;">:</td><td><div>/test/stress/stress</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">utcnow</td><td style="vertical-align:top;">:</td><td><div>datetime.datetime(2017, 1, 15, 13, 51, 59, 230150)</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">uuid</td><td style="vertical-align:top;">:</td><td><div>test/217.118.78.39.2017-01-15.13-51-59.a91149d5-b8df-4331-8575-aa7c04b33e9e</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">wsgi</td><td style="vertical-align:top;">:</td><td><div>&lt;gluon.main.LazyWSGI object at 0x7ff1cbbead50&gt;</div></td></tr></table></div>'
tRp66
sS'frames'
p67
(lp68
(dp69
S'file'
p70
S'/home/concordance/web2py/gluon/restricted.py'
p71
sS'dump'
p72
(dp73
S'environment'
p74
S"{'A': <class 'gluon.html.A'>, 'ANY_OF': <class 'gluon.validators.ANY_OF'>, 'Auth': <class 'gluon.tools.Auth'>, 'B': <class 'gluon.html.B'>, 'BEAUTIFY': <class 'gluon.html.BEAUTIFY'>, 'BODY': <class 'gluon.html.BODY'>, 'BR': <class 'gluon.html.BR'>, 'BUTTON': <class 'gluon.html.BUTTON'>, 'CAT': <class 'gluon.html.CAT'>, 'CENTER': <class 'gluon.html.CENTER'>, ...}"
p75
sS'ccode'
p76
S'<code object <module> at 0x7ff1cbbe09b0, file "/...applications/test/controllers/stress.py", line 3>'
p77
ssS'lnum'
p78
I220
sS'lines'
p79
(dp80
I224
S'        # do not encapsulate (obfuscate) the original RestrictedError'
p81
sI215
S'    try:'
p82
sI216
S'        if isinstance(code, types.CodeType):'
p83
sI217
S'            ccode = code'
p84
sI218
S'        else:'
p85
sI219
S'            ccode = compile2(code, layer)'
p86
sI220
S'        exec ccode in environment'
p87
sI221
S'    except HTTP:'
p88
sI222
S'        raise'
p89
sI223
S'    except RestrictedError:'
p90
ssS'call'
p91
S"(code='# coding: utf8\\n# \\xd0\\xbf\\xd0\\xbe\\xd0\\xbf\\xd1\\x80\\xd0\\xbe\\xd0\\xb1\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd1\\x8c \\xd1\\x87\\xd1\\x82\\xd0\\xbe-\\xd0...sg=msg)\\n\\nresponse._vars=response._caller(stress)\\n', environment={'A': <class 'gluon.html.A'>, 'ANY_OF': <class 'gluon.validators.ANY_OF'>, 'Auth': <class 'gluon.tools.Auth'>, 'B': <class 'gluon.html.B'>, 'BEAUTIFY': <class 'gluon.html.BEAUTIFY'>, 'BODY': <class 'gluon.html.BODY'>, 'BR': <class 'gluon.html.BR'>, 'BUTTON': <class 'gluon.html.BUTTON'>, 'CAT': <class 'gluon.html.CAT'>, 'CENTER': <class 'gluon.html.CENTER'>, ...}, layer='/home/concordance/web2py/applications/test/controllers/stress.py')"
p92
sS'func'
p93
S'restricted'
p94
sa(dp95
g70
S'/home/concordance/web2py/applications/test/controllers/stress.py'
p96
sg72
(dp97
sg78
I76
sg79
(dp98
I65
S"    filename = '/home/concordance/web2py/applications/test/rhymes/stress/zh.json'"
p99
sI66
S"    with open(filename, 'rb') as outfile:"
p100
sI67
S'        dd = json.load(outfile)'
p101
sI68
S'    l = []'
p102
sI69
S'    for key, i in dd.items():'
p103
sI70
S'        for word, s in i.items():'
p104
sI71
S'            #l.append([key, word, s])'
p105
sI72
S'            d.stress.insert(lemma = key, form = word, stress = s)'
p106
sI73
S'    msg = "\xd0\x92\xd1\x81\xd0\xb5"'
p107
sI74
S'    return dict(msg=msg)'
p108
ssg91
S'()'
p109
sg93
S'<module>'
p110
sa(dp111
g70
S'/home/concordance/web2py/gluon/globals.py'
p112
sg72
(dp113
S'self'
p114
S'undefined'
p115
sS'f'
S'<function stress>'
p116
ssg78
I385
sg79
(dp117
I384
S'        self._vars = None'
p118
sI385
S'        self._caller = lambda f: f()'
p119
sI386
S'        self._view_environment = None'
p120
sI387
S'        self._custom_commit = None'
p121
sI388
S'        self._custom_rollback = None'
p122
sI389
S''
sI380
S'        self.menu = []             # used by the default view layout'
p123
sI381
S'        self.files = []            # used by web2py_ajax.html'
p124
sI382
S'        self.generic_patterns = []  # patterns to allow generic views'
p125
sI383
S"        self.delimiters = ('{{', '}}')"
p126
ssg91
S'(f=<function stress>)'
p127
sg93
S'<lambda>'
p128
sa(dp129
g70
S'/home/concordance/web2py/applications/test/controllers/stress.py'
p130
sg72
(dp131
S'global nltk'
p132
S"<module 'nltk' from '/usr/local/lib/python2.7/dist-packages/nltk/__init__.pyc'>"
p133
sS'line'
p134
S"'\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n'"
p135
sS'line.lower'
p136
S'<built-in method lower of str object>'
p137
sS'words'
p138
g115
sS'nltk.word_tokenize'
p139
S'<function word_tokenize>'
p140
ssg78
I53
sg79
(dp141
I48
S'def stress():'
p142
sI49
S"    filename = '/home/concordance/web2py/applications/test/rhymes/1.txt'"
p143
sI50
S"    text = open(filename, 'r').readlines()"
p144
sI51
S'    textlines = []'
p145
sI52
S'    for line in text:'
p146
sI53
S'        words = nltk.word_tokenize(line.lower())'
p147
sI54
S'        words_new=[]'
p148
sI55
S'        for all in words:'
p149
sI56
S'            w = d(d.stress.form==all).select().first()'
p150
sI57
S'            if w:'
p151
ssg91
S'()'
p152
sg93
S'stress'
p153
sa(dp154
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/__init__.py'
p155
sg72
(dp156
S'text'
p157
S"'\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n'"
p158
sS'token'
p159
g115
sS'global sent_tokenize'
p160
S'<function sent_tokenize>'
p161
sS'sent'
p162
g115
sS'global _treebank_word_tokenize'
p163
S'<bound method TreebankWordTokenizer.tokenize of ....tokenize.treebank.TreebankWordTokenizer object>>'
p164
ssg78
I93
sg79
(dp165
I96
S'if __name__ == "__main__":'
p166
sI97
S'    import doctest'
p167
sI88
S'    Return a tokenized copy of *text*,'
p168
sI89
S"    using NLTK's recommended word tokenizer"
p169
sI90
S'    (currently :class:`.TreebankWordTokenizer`'
p170
sI91
S'    along with :class:`.PunktSentenceTokenizer`).'
p171
sI92
S'    """'
p172
sI93
S'    return [token for sent in sent_tokenize(text)'
p173
sI94
S'            for token in _treebank_word_tokenize(sent)]'
p174
sI95
S''
ssg91
S"(text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n')"
p175
sg93
S'word_tokenize'
p176
sa(dp177
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/__init__.py'
p178
sg72
(dp179
S'text'
p180
S"'\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n'"
p181
sS'tokenizer.tokenize'
p182
S'<bound method PunktSentenceTokenizer.tokenize of...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p183
sS'tokenizer'
p184
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p185
ssg78
I82
sg79
(dp186
I77
S'    Return a sentence-tokenized copy of *text*,'
p187
sI78
S"    using NLTK's recommended sentence tokenizer"
p188
sI79
S'    (currently :class:`.PunktSentenceTokenizer`).'
p189
sI80
S'    """'
p190
sI81
S"    tokenizer = load('tokenizers/punkt/english.pickle')"
p191
sI82
S'    return tokenizer.tokenize(text)'
p192
sI83
S''
sI84
S'# Standard word tokenizer.'
p193
sI85
S'_treebank_word_tokenize = TreebankWordTokenizer().tokenize'
p194
sI86
S'def word_tokenize(text):'
p195
ssg91
S"(text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n')"
p196
sg93
S'sent_tokenize'
p197
sa(dp198
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p199
sg72
(dp200
S'text'
p201
S"'\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n'"
p202
sS'self'
p203
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p204
sS'self.sentences_from_text'
p205
S'<bound method PunktSentenceTokenizer.sentences_f...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p206
sS'builtinlist'
p207
S"<type 'list'>"
p208
sS'realign_boundaries'
p209
S'True'
p210
ssg78
I1270
sg79
(dp211
I1265
S''
sI1266
S'    def tokenize(self, text, realign_boundaries=True):'
p212
sI1267
S'        """'
p213
sI1268
S'        Given a text, returns a list of the sentences in that text.'
p214
sI1269
S'        """'
p215
sI1270
S'        return list(self.sentences_from_text(text, realign_boundaries))'
p216
sI1271
S''
sI1272
S'    def debug_decisions(self, text):'
p217
sI1273
S'        """'
p218
sI1274
S'        Classifies candidate periods as sentence breaks, yielding a dict for'
p219
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n', realign_boundaries=True)"
p220
sg93
S'tokenize'
p221
sa(dp222
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p223
sg72
(dp224
S'self.span_tokenize'
p225
S'<bound method PunktSentenceTokenizer.span_tokeni...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p226
sS'e'
g115
sS'realign_boundaries'
p227
g210
sS'text'
p228
S"'\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n'"
p229
sS'self'
p230
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p231
sS's'
g115
ssg78
I1318
sg79
(dp232
I1313
S'        Given a text, generates the sentences in that text by only'
p233
sI1314
S'        testing candidate sentence breaks. If realign_boundaries is'
p234
sI1315
S'        True, includes in the sentence closing punctuation that'
p235
sI1316
S'        follows the period.'
p236
sI1317
S'        """'
p237
sI1318
S'        return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]'
p238
sI1319
S''
sI1320
S'    def _slices_from_text(self, text):'
p239
sI1321
S'        last_break = 0'
p240
sI1322
S'        for match in self._lang_vars.period_context_re().finditer(text):'
p241
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n', realign_boundaries=True)"
p242
sg93
S'sentences_from_text'
p243
sa(dp244
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p245
sg72
(dp246
S'slices'
p247
S'<generator object _realign_boundaries>'
p248
sS'sl'
p249
g115
ssg78
I1309
sg79
(dp250
I1312
S'        """'
p251
sI1313
S'        Given a text, generates the sentences in that text by only'
p252
sI1304
S'        in the text.'
p253
sI1305
S'        """'
p254
sI1306
S'        slices = self._slices_from_text(text)'
p255
sI1307
S'        if realign_boundaries:'
p256
sI1308
S'            slices = self._realign_boundaries(text, slices)'
p257
sI1309
S'        return [(sl.start, sl.stop) for sl in slices]'
p258
sI1310
S''
sI1311
S'    def sentences_from_text(self, text, realign_boundaries=True):'
p259
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n', realign_boundaries=True)"
p260
sg93
S'span_tokenize'
p261
sa(dp262
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p263
sg72
(dp264
S'global _pair_iter'
p265
S'<function _pair_iter>'
p266
sS'sl1'
p267
g115
sS'sl2'
p268
g115
sS'slices'
p269
S'<generator object _slices_from_text>'
p270
ssg78
I1348
sg79
(dp271
I1344
S''
sI1345
S'            ["(Sent1.)", "Sent2."].'
p272
sI1346
S'        """'
p273
sI1347
S'        realign = 0'
p274
sI1348
S'        for sl1, sl2 in _pair_iter(slices):'
p275
sI1349
S'            sl1 = slice(sl1.start + realign, sl1.stop)'
p276
sI1350
S'            if not sl2:'
p277
sI1351
S'                if text[sl1]:'
p278
sI1352
S'                    yield sl1'
p279
sI1343
S'        This method will produce::'
p280
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n', slices=<generator object _slices_from_text>)"
p281
sg93
S'_realign_boundaries'
p282
sa(dp283
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p284
sg72
(dp285
S'builtinnext'
p286
S'<built-in function next>'
p287
sS'prev'
p288
g115
sS'it'
p289
S'<generator object _slices_from_text>'
p290
ssg78
I354
sg79
(dp291
I352
S'    """'
p292
sI353
S'    it = iter(it)'
p293
sI354
S'    prev = next(it)'
p294
sI355
S'    for el in it:'
p295
sI356
S'        yield (prev, el)'
p296
sI357
S'        prev = el'
p297
sI358
S'    yield (prev, None)'
p298
sI349
S'    Yields pairs of tokens from the given iterator such that each input'
p299
sI350
S'    token will appear as the first element in a yielded tuple. The last'
p300
sI351
S'    pair will have None as its second element.'
p301
ssg91
S'(it=<generator object _slices_from_text>)'
p302
sg93
S'_pair_iter'
p303
sa(dp304
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p305
sg72
(dp306
S'self'
p307
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p308
sS'self.text_contains_sentbreak'
p309
S'<bound method PunktSentenceTokenizer.text_contai...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p310
sS'context'
p311
S"'\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9'"
p312
ssg78
I1324
sg79
(dp313
I1319
S''
sI1320
S'    def _slices_from_text(self, text):'
p314
sI1321
S'        last_break = 0'
p315
sI1322
S'        for match in self._lang_vars.period_context_re().finditer(text):'
p316
sI1323
S"            context = match.group() + match.group('after_tok')"
p317
sI1324
S'            if self.text_contains_sentbreak(context):'
p318
sI1325
S'                yield slice(last_break, match.end())'
p319
sI1326
S"                if match.group('next_tok'):"
p320
sI1327
S'                    # next sentence starts after whitespace'
p321
sI1328
S"                    last_break = match.start('next_tok')"
p322
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd0\\xa1\\xd0\\xb5\\xd1\\x80\\xd1\\x8b\\xd0\\xb9 \\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9 \\xd1\\x82\\xd0\\xbe\\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c.\\n')"
p323
sg93
S'_slices_from_text'
p324
sa(dp325
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p326
sg72
(dp327
S'self._tokenize_words'
p328
S'<bound method PunktSentenceTokenizer._tokenize_w...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p329
sS'self'
p330
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p331
sS'text'
p332
S"'\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9'"
p333
sS't'
g115
sS'self._annotate_tokens'
p334
S'<bound method PunktSentenceTokenizer._annotate_t...tk.tokenize.punkt.PunktSentenceTokenizer object>>'
p335
ssg78
I1369
sg79
(dp336
I1364
S'    def text_contains_sentbreak(self, text):'
p337
sI1365
S'        """'
p338
sI1366
S'        Returns True if the given text includes a sentence break.'
p339
sI1367
S'        """'
p340
sI1368
S'        found = False # used to ignore last token'
p341
sI1369
S'        for t in self._annotate_tokens(self._tokenize_words(text)):'
p342
sI1370
S'            if found:'
p343
sI1371
S'                return True'
p344
sI1372
S'            if t.sentbreak:'
p345
sI1373
S'                found = True'
p346
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, text='\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9')"
p347
sg93
S'text_contains_sentbreak'
p348
sa(dp349
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p350
sg72
(dp351
S'tokens'
p352
S'<generator object _annotate_first_pass>'
p353
sS'global _pair_iter'
p354
S'<function _pair_iter>'
p355
sS't2'
p356
g115
sS't1'
p357
g115
ssg78
I1504
sg79
(dp358
I1504
S'        for t1, t2 in _pair_iter(tokens):'
p359
sI1505
S'            self._second_pass_annotation(t1, t2)'
p360
sI1506
S'            yield t1'
p361
sI1507
S''
sI1508
S'    def _second_pass_annotation(self, aug_tok1, aug_tok2):'
p362
sI1499
S'        """'
p363
sI1500
S'        Performs a token-based classification (section 4) over the given'
p364
sI1501
S'        tokens, making use of the orthographic heuristic (4.1.1), collocation'
p365
sI1502
S'        heuristic (4.1.2) and frequent sentence starter heuristic (4.1.3).'
p366
sI1503
S'        """'
p367
ssg91
S'(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, tokens=<generator object _annotate_first_pass>)'
p368
sg93
S'_annotate_second_pass'
p369
sa(dp370
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p371
sg72
(dp372
S'builtinnext'
p373
S'<built-in function next>'
p374
sS'prev'
p375
g115
sS'it'
p376
S'<generator object _annotate_first_pass>'
p377
ssg78
I354
sg79
(dp378
I352
S'    """'
p379
sI353
S'    it = iter(it)'
p380
sI354
S'    prev = next(it)'
p381
sI355
S'    for el in it:'
p382
sI356
S'        yield (prev, el)'
p383
sI357
S'        prev = el'
p384
sI358
S'    yield (prev, None)'
p385
sI349
S'    Yields pairs of tokens from the given iterator such that each input'
p386
sI350
S'    token will appear as the first element in a yielded tuple. The last'
p387
sI351
S'    pair will have None as its second element.'
p388
ssg91
S'(it=<generator object _annotate_first_pass>)'
p389
sg93
g303
sa(dp390
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p391
sg72
(dp392
S'tokens'
p393
S'<generator object _tokenize_words>'
p394
sS'aug_tok'
p395
g115
ssg78
I621
sg79
(dp396
I616
S''
sI617
S'          - sentbreak_toks: The indices of all sentence breaks.'
p397
sI618
S'          - abbrev_toks: The indices of all abbreviations.'
p398
sI619
S'          - ellipsis_toks: The indices of all ellipsis marks.'
p399
sI620
S'        """'
p400
sI621
S'        for aug_tok in tokens:'
p401
sI622
S'            self._first_pass_annotation(aug_tok)'
p402
sI623
S'            yield aug_tok'
p403
sI624
S''
sI625
S'    def _first_pass_annotation(self, aug_tok):'
p404
ssg91
S'(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, tokens=<generator object _tokenize_words>)'
p405
sg93
S'_annotate_first_pass'
p406
sa(dp407
g70
S'/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py'
p408
sg72
(dp409
S'plaintext'
p410
S"'\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9'"
p411
sS'plaintext.split'
p412
S'<built-in method split of str object>'
p413
sS'line'
p414
g115
ssg78
I586
sg79
(dp415
I581
S'        of tokens augmented as three-tuples with two boolean values for whether'
p416
sI582
S'        the given token occurs at the start of a paragraph or a new line,'
p417
sI583
S'        respectively.'
p418
sI584
S'        """'
p419
sI585
S'        parastart = False'
p420
sI586
S"        for line in plaintext.split('\\n'):"
p421
sI587
S'            if line.strip():'
p422
sI588
S'                line_toks = iter(self._lang_vars.word_tokenize(line))'
p423
sI589
S''
sI590
S'                yield self._Token(next(line_toks),'
p424
ssg91
S"(self=<nltk.tokenize.punkt.PunktSentenceTokenizer object>, plaintext='\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9')"
p425
sg93
S'_tokenize_words'
p426
sasS'pyver'
p427
S'Python 2.7.6: /usr/local/bin/uwsgi (prefix: /usr)'
p428
sS'session'
p429
g65
(S's\xcf\x01\x00\x00<div><table><tr><td style="font-weight:bold;vertical-align:top;">flash</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">last_orderby</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">last_query</td><td style="vertical-align:top;">:</td><td><div>d.stress.form==&#x27;\xd1\x82\xd1\x8f\xd0\xb6\xd0\xba\xd0\xb8\xd1\x85&#x27;</div></td></tr></table></div>'
tRp430
sS'etype'
p431
S"<type 'exceptions.UnicodeDecodeError'>"
p432
sS'date'
p433
S'Sun Jan 15 13:51:59 2017'
p434
sS'response'
p435
g65
(S's\x80\x1e\x00\x00<div><table><tr><td style="font-weight:bold;vertical-align:top;">body</td><td style="vertical-align:top;">:</td><td><div>&lt;cStringIO.StringO object at 0x7ff1d09eca40&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">cookies</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">session_id_test</td><td style="vertical-align:top;">:</td><td><div>46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436<table><tr><td style="font-weight:bold;vertical-align:top;">comment</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">domain</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">expires</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">httponly</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">max-age</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">path</td><td style="vertical-align:top;">:</td><td><div>/</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">secure</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">version</td><td style="vertical-align:top;">:</td><td><div></div></td></tr></table></div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">delimiters</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>{{</div></td></tr><tr><td><div>}}</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">files</td><td style="vertical-align:top;">:</td><td><div><table></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">flash</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">generic_patterns</td><td style="vertical-align:top;">:</td><td><div><table></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">google_analytics_id</td><td style="vertical-align:top;">:</td><td><div>UA-52567545-1</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">headers</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">X-Powered-By</td><td style="vertical-align:top;">:</td><td><div>web2py</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">logo</td><td style="vertical-align:top;">:</td><td><div><a class="brand" href="http://concordances.ru"><b>concor<span>dances</span></b>.ru</a></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">menu</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div><table><tr><td><div>Home</div></td></tr><tr><td><div>False</div></td></tr><tr><td><div>/test/default/index</div></td></tr><tr><td><div><table></table></div></td></tr></table></div></td></tr><tr><td><div><table><tr><td><div><span class="highlighted">web2py</span></div></td></tr><tr><td><div>False</div></td></tr><tr><td><div>http://concordances.ru</div></td></tr><tr><td><div><table><tr><td><div><table><tr><td><div>\xd0\x9e \xd0\xbf\xd1\x80\xd0\xbe\xd0\xb5\xd0\xba\xd1\x82\xd0\xb5</div></td></tr><tr><td><div>False</div></td></tr><tr><td><div>/admin/default/about/test</div></td></tr></table></div></td></tr><tr><td><div><table><tr><td><div>\xd0\x90\xd0\xb4\xd0\xbc\xd0\xb8\xd0\xbd\xd0\xba\xd0\xb0</div></td></tr><tr><td><div>False</div></td></tr><tr><td><div>/admin/default/edit/test/controllers/stress.py</div></td></tr></table></div></td></tr></table></div></td></tr></table></div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">meta</td><td style="vertical-align:top;">:</td><td><div><table><tr><td style="font-weight:bold;vertical-align:top;">author</td><td style="vertical-align:top;">:</td><td><div>Maria Levchenko &lt;marylevchenko@gmail.com&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">generator</td><td style="vertical-align:top;">:</td><td><div>\xd0\xa7\xd0\xb0\xd1\x81\xd1\x82\xd0\xbe\xd1\x82\xd0\xbd\xd1\x8b\xd0\xb9 \xd1\x81\xd0\xbb\xd0\xbe\xd0\xb2\xd0\xb0\xd1\x80\xd1\x8c \xd1\x80\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xbe\xd0\xb9 \xd0\xbb\xd0\xb8\xd1\x82\xd0\xb5\xd1\x80\xd0\xb0\xd1\x82\xd1\x83\xd1\x80\xd1\x8b</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">keywords</td><td style="vertical-align:top;">:</td><td><div>concordance, natural language processing, critics</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">models_to_run</td><td style="vertical-align:top;">:</td><td><div><table><tr><td><div>^\\w+\\.py$</div></td></tr><tr><td><div>^stress/\\w+\\.py$</div></td></tr><tr><td><div>^stress/stress/\\w+\\.py$</div></td></tr></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">postprocessing</td><td style="vertical-align:top;">:</td><td><div><table></table></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_client</td><td style="vertical-align:top;">:</td><td><div>217.118.78.39</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_cookie_compression_level</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_cookie_expires</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_cookie_key</td><td style="vertical-align:top;">:</td><td><div>None</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_data_name</td><td style="vertical-align:top;">:</td><td><div>session_data_test</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_file</td><td style="vertical-align:top;">:</td><td><div>&lt;open file &#x27;/home/concordance/web2py/applications/test/sessions/46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436&#x27;, mode &#x27;rb+&#x27; at 0x7ff1ca2cfd20&gt;</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_filename</td><td style="vertical-align:top;">:</td><td><div>/home/concordance/web2py/applications/test/sessions/46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_hash</td><td style="vertical-align:top;">:</td><td><div>b99b21c4b2ba01ab42dad69cd5668c04</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_id</td><td style="vertical-align:top;">:</td><td><div>46.101.16.229-06e011a5-7dfa-444f-aa81-2f76a54cf436</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_id_name</td><td style="vertical-align:top;">:</td><td><div>session_id_test</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_locked</td><td style="vertical-align:top;">:</td><td><div>True</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_masterapp</td><td style="vertical-align:top;">:</td><td><div>test</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_new</td><td style="vertical-align:top;">:</td><td><div>False</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">session_storage_type</td><td style="vertical-align:top;">:</td><td><div>file</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">status</td><td style="vertical-align:top;">:</td><td><div>200</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">subtitle</td><td style="vertical-align:top;">:</td><td><div></div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">title</td><td style="vertical-align:top;">:</td><td><div>Test</div></td></tr><tr><td style="font-weight:bold;vertical-align:top;">view</td><td style="vertical-align:top;">:</td><td><div>stress/stress.html</div></td></tr></table></div>'
tRp436
sS'locals'
p437
(dp438
S'plaintext'
p439
S"'\\xd1\\x88\\xd0\\xb8\\xd1\\x84\\xd0\\xb5\\xd1\\x80. \\xd0\\x91\\xd0\\xb5\\xd0\\xbb\\xd1\\x8b\\xd0\\xb9'"
p440
sS'self'
p441
S'<nltk.tokenize.punkt.PunktSentenceTokenizer object>'
p442
sS'parastart'
p443
S'False'
p444
sssS'traceback'
p445
S'Traceback (most recent call last):\n  File "/home/concordance/web2py/gluon/restricted.py", line 220, in restricted\n    exec ccode in environment\n  File "/home/concordance/web2py/applications/test/controllers/stress.py", line 76, in <module>\n  File "/home/concordance/web2py/gluon/globals.py", line 385, in <lambda>\n    self._caller = lambda f: f()\n  File "/home/concordance/web2py/applications/test/controllers/stress.py", line 53, in stress\n    words = nltk.word_tokenize(line.lower())\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/__init__.py", line 93, in word_tokenize\n    return [token for sent in sent_tokenize(text)\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/__init__.py", line 82, in sent_tokenize\n    return tokenizer.tokenize(text)\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1270, in tokenize\n    return list(self.sentences_from_text(text, realign_boundaries))\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1318, in sentences_from_text\n    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1309, in span_tokenize\n    return [(sl.start, sl.stop) for sl in slices]\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1348, in _realign_boundaries\n    for sl1, sl2 in _pair_iter(slices):\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 354, in _pair_iter\n    prev = next(it)\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1324, in _slices_from_text\n    if self.text_contains_sentbreak(context):\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1369, in text_contains_sentbreak\n    for t in self._annotate_tokens(self._tokenize_words(text)):\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 1504, in _annotate_second_pass\n    for t1, t2 in _pair_iter(tokens):\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 354, in _pair_iter\n    prev = next(it)\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 621, in _annotate_first_pass\n    for aug_tok in tokens:\n  File "/usr/local/lib/python2.7/dist-packages/nltk/tokenize/punkt.py", line 586, in _tokenize_words\n    for line in plaintext.split(\'\\n\'):\nUnicodeDecodeError: \'ascii\' codec can\'t decode byte 0xd1 in position 0: ordinal not in range(128)\n'
p446
s.