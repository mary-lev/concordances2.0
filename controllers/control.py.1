# coding: utf8
import nltk
import pymorphy2
from tokenize1 import *
import os
from os import listdir
from os.path import isfile, join
from operator import itemgetter
import subprocess
import select
from lxml import etree
from plugin_sqleditable.editable import SQLEDITABLE
SQLEDITABLE.init()

def index():
    texts = text().select(text.author.ALL, orderby=text.author.id)
    return dict(texts=texts)

def all_texts():
    texts = text().select(text.text.ALL, orderby=text.text.id)
    return dict(texts=texts)

def show1():   # show text from file
    texts = text(text.text.id==request.args(0)).select().first()
    f = open(texts.filename, 'rb')
    content = f.readlines()
    return dict(texts=texts, content=content)

def show2(): # color the verbs
    words = text(text.words.title==request.args(0)).select()
    content = []
    for row in words:
        if row.partos=='VERB':
            new_words=str(row.lemma)+str('&')
            content.append(new_words)
        else:
            content.append(row.lemma)
    return dict(content=content)

def show3():
    texts = text(text.text.id==request.args(0)).select().first()
    rows = text(text.words.title==request.args(0)).select()
    text_view = []
    for row in rows:
        text_view.append((row.lemma, row.id))
    options = [OPTION(row.lemma, _value=row.id) for row in rows]
    form=FORM(TABLE(TR("Выберите текст"),
                    TR("Например, так:",SELECT(*options, _name="first")),
                    TR("",INPUT(_type="submit",_value="SUBMIT"))))
    if form.accepts(request,session):
        response.flash="form accepted"
    return dict(text_view=text_view, form=form)

def tokenize_all(): # prepares text for tokenization (decoding) and write result in database text.words
    for x in range(1000,1061): # if text not yet in database text.words
        text2 = text(text.text.id==x).select().first()
        text1 = text2['body'].decode('utf-8')
        path = "/home/concordance/web2py/applications/test/uploads/"
        filename1=str(text2.author.id) + "_" + str(text2.n_in_group) + "_" + str(text2.id) + str('.txt')
        filename= str(path) + str(filename1)
        f = open(filename, 'w')
        f.write(text1.encode('utf-8'))
        f.close()
        text2.update_record(filename=filename)
        normal = normalize_new2(text1)
        for token in normal:
            text.words.insert(title=text2.id, word=token[0], partos=str(token[1]), author=text2.author, text_location=token[3], tense=str(token[4]), lemma=str(token[2].encode('utf-8')))
            message = "Все добавлено в базу"
    return dict(message=message)

def tokenize_new(): # prepares text for tokenization (decoding) and write result in database text.words
    base_id = [int(all.title) for all in text().select(text.words.ALL)]
    if int(request.args(0)) not in base_id: # if text not yet in database text.words
        text2 = text(text.text.id==request.args(0)).select().first()
        text1 = text2['body'].decode('utf-8')
        path = "/home/concordance/web2py/applications/test/uploads/"
        filename1=str(text2.author.id) + "_" + str(text2.n_in_group) + "_" + str(text2.id) + str('.txt')
        filename= str(path) + str(filename1)
        f = open(filename, 'w')
        f.write(text1.encode('utf-8'))
        f.close()
        text2.update_record(filename=filename)
        normal = normalize_new2(text1)
        for token in normal:
            text.words.insert(title=text2.id, word=token[0], partos=str(token[1]), author=text2.author, text_location=token[3], tense=str(token[4]), lemma=str(token[2].encode('utf-8')))
            message = "Все добавлено в базу"
    else:
        message = "Все уже в базе"
    return dict(message=message)

def search_for_files():
    path = "/home/concordance/web2py/applications/test/corpus/"
    files = [f for f in listdir(path) if isfile(join(path,f)) ]
    return dict(files=files)

def verbs_all(): # show verbs in the text
    verbs1=[row['word'] for row in text((text.words.author=='1')&(text.words.partos=='VERB')).select()]
    verbs1=sorted(set(verbs1))
    return dict(verbs1=verbs1)

def concordance(): # concordance of one text
    all_words = text(text.words.title==request.args(0)).select()
    lens=len(all_words)
    vocab = []
    for row in all_words:
        w = row.word
        q = text((text.words.word==row.word)&(text.words.title==request.args(0))).select()
        qq = round(((len(q)/float(lens))*100), 2)
        c = [w, len(q), qq]
        if c not in vocab:
            vocab.append(c)
    vocab.sort(key = itemgetter(0), reverse=False)
    return dict(lens=lens, vocab=vocab)

def mystem():
    word="стояла"
    path = "/home/concordance/mystem/"
    myste=subprocess.Popen([path, '-nlc', '-e utf-8'],
                                        stdout=subprocess.PIPE,
                                        stdin=subprocess.PIPE, shell=True)
    new=myste.stdin.write(word)
    readable, _, _ = select.select([myste.stdout], [], [], 5e-3)
    stem = readable[0].readline().strip().lower()
    return dict(new=new, stem=stem)

def edit_forms():
    def record():
        rows = text(text.words.title ==request.args(0)).select()
        return [row.id for row in rows]
    text.words.id.readable = True
    text.words.word.writable = True
    text.words.title.readable = True
    text.words.partos.writable = True
    text.words.tense.writable = True
    text.words.lexical_group.writable=True
    text.words.lemma.writable=True

    response.title = 'demo020'
    response.view = 'plugin_sqleditable/sample.html'
    editable = SQLEDITABLE(text.words, record=record(), deletable=True).process()
    return dict(editable=editable)

def years():
    all_years = [int(all.year_writing) for all in text().select(text.text.ALL if all.year_writing!='None']
    year=[]
    year_sorted=sorted(set(all_years))
    for x in year_sorted:
        try:
            year_writing = text(text.text.year_writing==x).count()
            year.append((x, year_writing))
        else:
            pass
    month = [(x, text(text.text.month_writing==x).count()) for x in range(1,13)]
    return dict(year=year, year_sorted=year_sorted, month=month)

def month():
    months = [(x, text(text.text.month_writing==x).count()) for x in range(1,13)]
    return dict(months=months)

def create_xml():
    texts = text(text.text.id==request.args(0)).select().first()
    f = open(texts.filename, 'rb')
    content = f.readlines()
    root = etree.Element('root')
    root.append(etree.Element('child'))
    for lines in content:
        child = etree.Element('child')
        child.text = lines
        root.append(child)
    tree = etree.ElementTree(root)
    tree.write("filename.xml")
    #new_name=texts.filename+".xml"
    #etree.write(new_name)
